{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcPWRPzSyIlM",
        "outputId": "25a97e5f-f3ea-43d8-db17-9f80e42aafc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "pkg-config is already the newest version (0.29.2-1ubuntu3).\n",
            "graphviz is already the newest version (2.42.2-6).\n",
            "python3-dev is already the newest version (3.10.6-1~22.04).\n",
            "python3-dev set to manually installed.\n",
            "The following additional packages will be installed:\n",
            "  libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin libgtk2.0-common libgvc6-plugins-gtk\n",
            "  librsvg2-common libxdot4\n",
            "Suggested packages:\n",
            "  gvfs\n",
            "The following NEW packages will be installed:\n",
            "  libgail-common libgail18 libgraphviz-dev libgtk2.0-0 libgtk2.0-bin libgtk2.0-common\n",
            "  libgvc6-plugins-gtk librsvg2-common libxdot4\n",
            "0 upgraded, 9 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 2,433 kB of archives.\n",
            "After this operation, 7,694 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-common all 2.24.33-2ubuntu2 [125 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-0 amd64 2.24.33-2ubuntu2 [2,037 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgail18 amd64 2.24.33-2ubuntu2 [15.9 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgail-common amd64 2.24.33-2ubuntu2 [132 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libxdot4 amd64 2.42.2-6 [16.4 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgvc6-plugins-gtk amd64 2.42.2-6 [22.6 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libgraphviz-dev amd64 2.42.2-6 [58.5 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgtk2.0-bin amd64 2.24.33-2ubuntu2 [7,932 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 librsvg2-common amd64 2.52.5+dfsg-3ubuntu0.2 [17.7 kB]\n",
            "Fetched 2,433 kB in 1s (2,707 kB/s)\n",
            "Selecting previously unselected package libgtk2.0-common.\n",
            "(Reading database ... 121920 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libgtk2.0-common_2.24.33-2ubuntu2_all.deb ...\n",
            "Unpacking libgtk2.0-common (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgtk2.0-0:amd64.\n",
            "Preparing to unpack .../1-libgtk2.0-0_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgtk2.0-0:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgail18:amd64.\n",
            "Preparing to unpack .../2-libgail18_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgail18:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libgail-common:amd64.\n",
            "Preparing to unpack .../3-libgail-common_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgail-common:amd64 (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package libxdot4:amd64.\n",
            "Preparing to unpack .../4-libxdot4_2.42.2-6_amd64.deb ...\n",
            "Unpacking libxdot4:amd64 (2.42.2-6) ...\n",
            "Selecting previously unselected package libgvc6-plugins-gtk.\n",
            "Preparing to unpack .../5-libgvc6-plugins-gtk_2.42.2-6_amd64.deb ...\n",
            "Unpacking libgvc6-plugins-gtk (2.42.2-6) ...\n",
            "Selecting previously unselected package libgraphviz-dev:amd64.\n",
            "Preparing to unpack .../6-libgraphviz-dev_2.42.2-6_amd64.deb ...\n",
            "Unpacking libgraphviz-dev:amd64 (2.42.2-6) ...\n",
            "Selecting previously unselected package libgtk2.0-bin.\n",
            "Preparing to unpack .../7-libgtk2.0-bin_2.24.33-2ubuntu2_amd64.deb ...\n",
            "Unpacking libgtk2.0-bin (2.24.33-2ubuntu2) ...\n",
            "Selecting previously unselected package librsvg2-common:amd64.\n",
            "Preparing to unpack .../8-librsvg2-common_2.52.5+dfsg-3ubuntu0.2_amd64.deb ...\n",
            "Unpacking librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libxdot4:amd64 (2.42.2-6) ...\n",
            "Setting up librsvg2-common:amd64 (2.52.5+dfsg-3ubuntu0.2) ...\n",
            "Setting up libgtk2.0-common (2.24.33-2ubuntu2) ...\n",
            "Setting up libgtk2.0-0:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgvc6-plugins-gtk (2.42.2-6) ...\n",
            "Setting up libgail18:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgtk2.0-bin (2.24.33-2ubuntu2) ...\n",
            "Setting up libgail-common:amd64 (2.24.33-2ubuntu2) ...\n",
            "Setting up libgraphviz-dev:amd64 (2.42.2-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libgdk-pixbuf-2.0-0:amd64 (2.42.8+dfsg-1ubuntu0.2) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get install python3-dev graphviz libgraphviz-dev pkg-config"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU \\\n",
        "    langchain-openai==0.1.3 \\\n",
        "    langchain==0.1.16 \\\n",
        "    langchain-core==0.1.42 \\\n",
        "    langgraph==0.0.37 \\\n",
        "    langchainhub==0.1.15 \\\n",
        "    pygraphviz==1.12 \\\n",
        "    langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2326XExHyJfC",
        "outputId": "c43421f6-be1f-45db-a142-6189b14e45b3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.5/287.5 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/104.9 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.9/312.9 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.7/116.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.5/142.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pygraphviz (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
        "\n",
        "retriever = TavilySearchAPIRetriever(k=3)"
      ],
      "metadata": {
        "id": "2YUDRru-yvN3"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List, Union\n",
        "from langchain_core.agents import AgentAction, AgentFinish\n",
        "import operator\n",
        "\n",
        "\n",
        "class AgentState(TypedDict):\n",
        "    input: str\n",
        "    agent_out: Union[AgentAction, AgentFinish, None]\n",
        "    intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]\n"
      ],
      "metadata": {
        "id": "dmzP7iaVyLyo"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_community.retrievers import TavilySearchAPIRetriever\n",
        "\n",
        "@tool(\"search\")\n",
        "def search_tool(query: str):\n",
        "    \"\"\"Searches for information on the topic of artificial intelligence (AI).\n",
        "    Cannot be used to research any other topics. Search query must be provided\n",
        "    in natural language and be verbose.\"\"\"\n",
        "    retriever = TavilySearchAPIRetriever(k=1)\n",
        "\n",
        "    # this is a \"RAG\" emulator\n",
        "    return retriever\n",
        "\n",
        "@tool(\"final_answer\")\n",
        "def final_answer_tool(\n",
        "    answer: str,\n",
        "    source: str\n",
        "):\n",
        "    \"\"\"Returns a natural language response to the user in `answer`, and a\n",
        "    `source` which provides citations for where this information came from.\n",
        "    \"\"\"\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "Uw2TP7svycfT"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -q langchain-groq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sfnuZ2-42BDw",
        "outputId": "8e2d792c-383e-481f-f05c-2739fc5e58c7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/302.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.8/302.8 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain.agents import create_openai_tools_agent\n",
        "from langchain import hub\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from google.colab import userdata\n",
        "from langchain_groq import ChatGroq\n",
        "\n",
        "os.environ[\"GROQ_API_KEY\"] = userdata.get(\"GROQ_API_KEY\")\n",
        "os.environ[\"TAVILY_API_KEY\"] = userdata.get(\"TAVILY_API_KEY\")\n",
        "\n",
        "\n",
        "\n",
        "llm = ChatGroq(\n",
        "            model=\"llama3-70b-8192\",\n",
        "        )\n",
        "\n",
        "prompt = hub.pull(\"hwchase17/openai-functions-agent\")\n",
        "\n",
        "query_agent_runnable = create_openai_tools_agent(\n",
        "    llm=llm,\n",
        "    tools=[final_answer_tool, search_tool],\n",
        "    prompt=prompt\n",
        ")"
      ],
      "metadata": {
        "id": "Z3sQgFR2yoQv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = {\n",
        "    \"input\": \"what are EHI embeddings?\",\n",
        "    \"intermediate_steps\": []\n",
        "}\n",
        "agent_out = query_agent_runnable.invoke(inputs)\n",
        "agent_out"
      ],
      "metadata": {
        "id": "wDFK9TVd1KF1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0ca016-0f63-4f07-ea43-99fc38ddb1eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[ToolAgentAction(tool='search', tool_input={'query': 'EHIs'}, log=\"\\nInvoking: `search` with `{'query': 'EHIs'}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_md7d', 'function': {'arguments': '{\"query\":\"EHIs\"}', 'name': 'search'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_time': 0.193, 'completion_tokens': 60, 'prompt_time': 0.973, 'prompt_tokens': 1070, 'queue_time': None, 'total_time': 1.166, 'total_tokens': 1130}, 'model_name': 'llama3-70b-8192', 'system_fingerprint': 'fp_87cbfbbc4d', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-3bb16015-67d8-4ecc-9764-c96b13e9c99f-0', tool_calls=[{'name': 'search', 'args': {'query': 'EHIs'}, 'id': 'call_md7d'}])], tool_call_id='call_md7d')]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.agents import AgentFinish\n",
        "import json\n",
        "\n",
        "def run_query_agent(state: list):\n",
        "    print(\"> run_query_agent\")\n",
        "    agent_out = query_agent_runnable.invoke(state)\n",
        "    return {\"agent_out\": agent_out}\n",
        "\n",
        "def execute_search(state: list):\n",
        "    print(\"> execute_search\")\n",
        "    action = state[\"agent_out\"]\n",
        "    tool_call = action[-1].message_log[-1].additional_kwargs[\"tool_calls\"][-1]\n",
        "    out = search_tool.invoke(\n",
        "        json.loads(tool_call[\"function\"][\"arguments\"])\n",
        "    )\n",
        "    return {\"intermediate_steps\": [{\"search\": str(out)}]}\n",
        "\n",
        "def router(state: list):\n",
        "    print(\"> router\")\n",
        "    if isinstance(state[\"agent_out\"], list):\n",
        "        return state[\"agent_out\"][-1].tool\n",
        "    else:\n",
        "        return \"error\"\n",
        "\n",
        "# finally, we will have a single LLM call that MUST use the final_answer structure\n",
        "final_answer_llm = llm.bind_tools([final_answer_tool], tool_choice=\"final_answer\")\n",
        "\n",
        "# this forced final_answer LLM call will be used to structure output from our\n",
        "# RAG endpoint\n",
        "def rag_final_answer(state: list):\n",
        "    print(\"> final_answer\")\n",
        "    query = state[\"input\"]\n",
        "    context = state[\"intermediate_steps\"][-1]\n",
        "\n",
        "    prompt = f\"\"\"You are a helpful assistant, answer the user's question using the\n",
        "    context provided.\n",
        "\n",
        "    CONTEXT: {context}\n",
        "\n",
        "    QUESTION: {query}\n",
        "    \"\"\"\n",
        "    out = final_answer_llm.invoke(prompt)\n",
        "    function_call = out.additional_kwargs[\"tool_calls\"][-1][\"function\"][\"arguments\"]\n",
        "    return {\"agent_out\": function_call}\n",
        "\n",
        "# we use the same forced final_answer LLM call to handle incorrectly formatted\n",
        "# output from our query_agent\n",
        "def handle_error(state: list):\n",
        "    print(\"> handle_error\")\n",
        "    query = state[\"input\"]\n",
        "    prompt = f\"\"\"You are a helpful assistant, answer the user's question.\n",
        "\n",
        "    QUESTION: {query}\n",
        "    \"\"\"\n",
        "    out = final_answer_llm.invoke(prompt)\n",
        "    function_call = out.additional_kwargs[\"tool_calls\"][-1][\"function\"][\"arguments\"]\n",
        "    return {\"agent_out\": function_call}"
      ],
      "metadata": {
        "id": "9rn6meDi1Q_J"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "graph = StateGraph(AgentState)\n",
        "\n",
        "graph.add_node(\"query_agent\", run_query_agent)\n",
        "graph.add_node(\"search\", execute_search)\n",
        "graph.add_node(\"error\", handle_error)\n",
        "graph.add_node(\"rag_final_answer\", rag_final_answer)\n",
        "\n",
        "graph.set_entry_point(\"query_agent\")\n",
        "\n",
        "# conditional edges are controlled by our router\n",
        "graph.add_conditional_edges(\n",
        "    start_key=\"query_agent\",  # where in graph to start\n",
        "    condition=router,  # function to determine which node is called\n",
        "    conditional_edge_mapping={\n",
        "        \"search\": \"search\",\n",
        "        \"error\": \"error\",\n",
        "        \"final_answer\": END\n",
        "    }\n",
        ")\n",
        "graph.add_edge(\"search\", \"rag_final_answer\")\n",
        "graph.add_edge(\"error\", END)\n",
        "graph.add_edge(\"rag_final_answer\", END)\n",
        "\n",
        "runnable = graph.compile()"
      ],
      "metadata": {
        "id": "VaKLx2ym8msL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "Image(runnable.get_graph().draw_png())"
      ],
      "metadata": {
        "id": "NzlmrtqA8qIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "runnable = graph.compile()\n",
        "\n",
        "out = runnable.invoke({\n",
        "    \"input\": \"what is AI?\",\n",
        "    \"chat_history\": []\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOOzvvHQ8sIk",
        "outputId": "41a31643-5bb0-484a-a738-a43419416c01"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> run_query_agent\n",
            "> router\n",
            "> execute_search\n",
            "> final_answer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out[\"agent_out\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oLmLGmC_WID",
        "outputId": "553216fd-4800-4182-abcc-d60056d92047"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"answer\":\"AI, or Artificial Intelligence, refers to the development of computer systems that can perform tasks that typically require human intelligence, such as understanding language, recognizing images, making decisions, and solving problems.\",\"source\":\"AI Definition\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = runnable.invoke({\n",
        "    \"input\": \"what are EHI embeddings?\",\n",
        "    \"chat_history\": []\n",
        "})\n",
        "print(out[\"agent_out\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LR6TXHHC_YHX",
        "outputId": "a6149092-ba12-4f78-d053-58eada12fd47"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> run_query_agent\n",
            "> router\n",
            "> execute_search\n",
            "> final_answer\n",
            "{\"answer\":\"EHI (Efficient Hierarchical Indexing) embeddings are a type of dense vector representation used in natural language processing and information retrieval. They are particularly useful for efficient similarity search and clustering of high-dimensional data.\",\"source\":\"Various research papers and articles on natural language processing and information retrieval.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(out[\"agent_out\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMp6q8JQ_bnv",
        "outputId": "b5b6a932-2ce3-4a40-b7dc-0049ba580065"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"answer\":\"EHI (Efficient Hierarchical Indexing) embeddings are a type of dense vector representation used in natural language processing and information retrieval. They are particularly useful for efficient similarity search and clustering of high-dimensional data.\",\"source\":\"Various research papers and articles on natural language processing and information retrieval.\"}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dDEBCX0m_ezJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}